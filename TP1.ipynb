{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jWUX78DM7n9T"
      },
      "source": [
        "# Temas Tratados en el Trabajo Práctico 1\n",
        "\n",
        "* Diferencia entre Inteligencia e Inteligencia Artificial.\n",
        "\n",
        "* Concepto de omnisciencia, aprendizaje y autonomía.\n",
        "\n",
        "* Definición de Agente y sus características. Clasificación de Agentes según su estructura.\n",
        "\n",
        "* Identificación y categorización del Entorno de Trabajo en tabla REAS.\n",
        "\n",
        "* Caracterización del Entorno de Trabajo.\n",
        "\n",
        "# Anotaciones\n",
        "\n",
        "\"Acordarse de la definición de agente\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicios Teóricos\n",
        "\n",
        "1. Defina con sus propias palabras inteligencia natural, inteligencia artificial y agente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inteligencia natural es la inteligencia que posee el ser humano, es creativa, esta basada tanto en experiencias como emociones. La inteligencia artificial por otra parte es la inteligencia asociada a los agentes inteligentes creados por el ser humano. Un agente es todo aquel dispositivo o software que puede percibir el entorno y presenta un cierto nivel de inteligencia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "2. ¿Qué es un agente racional?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Un agente racional es aquel que, para cada secuencia de percepciones que recibe de su entorno, elige la acción que maximiza su medida de rendimiento, basándose en la información provista por esas percepciones, el conocimiento que ya tiene sobre el mundo y las acciones que puede realizar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. ¿Un agente es siempre una computadora?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No necesariamente. Decimos que un agente cualquier cosa que tenga cierto nivel de inteligencia, es decir, que reconozca estimulos del entorno y a partir de estos responda en consecuencia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Defina Omnisciencia, Aprendizaje y Autonomía."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Omniscinecia: Es la capacidad de conocer el estado real y completo del entorno en todo momento. Es un ideal teórico: ningún agente real puede ser completamente omnisciente, porque el mundo es complejo, dinámico y con información oculta.\n",
        "\n",
        "Aprendizaje: Es la capacidad de mejorar su rendimiento con la experiencia. Un agente que aprende utiliza sus percepciones no solo para actuar, sino también para ajustar su forma de actuar en el futuro. Detecta patrones, predice consecuencias y optimiza decisiones con el tiempo.\n",
        "\n",
        "Autonomía: Mide cuánto dependen las acciones del agente de su propia experiencia frente a depender de conocimiento dado de antemano por el diseñador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Defina cada tipo de agente en función de su **estructura** y dé un ejemplo de cada categoría."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Agentes reactivos:** es un sistema que toma decisiones basadas únicamente en el estado actual del entorno, sin considerar el pasado ni planificar acciones futuras. \n",
        "*Por ejemplo: Termostato, sistemas de deteccion de spam.*\n",
        "\n",
        "**Agentes basados en objetivos:** es un tipo de sistema de inteligencia artificial diseñado para alcanzar metas específicas. Estos agentes evalúan su entorno, planifican acciones y toman decisiones basadas en cómo esas acciones afectarán su progreso hacia el objetivo deseado. \n",
        "*Por ejemplo: Sistemas de navegacion GPS, Agentes de atencion al cliente.*\n",
        "\n",
        "**Agentes que aprenden:** Los agentes de aprendizaje aprenden continuamente de las experiencias anteriores para mejorar sus resultados. Mediante mecanismos de información sensorial y comentarios, el agente adapta su elemento de aprendizaje a lo largo del tiempo para cumplir con estándares específicos. \n",
        "*Por ejemplo: motores de recomendacion, asistentes personales inteligentes*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Para los siguientes entornos de trabajo indique sus **propiedades**:\n",
        "\n",
        "        a. Una partida de ajedrez.\n",
        "\n",
        "        * Totalmente observable\n",
        "        * Determinista\n",
        "        * Secuencial\n",
        "        * Estático\n",
        "        * Discreto\n",
        "        * Multiagente\n",
        "\n",
        "        b. Un partido de baloncesto.\n",
        "\n",
        "        * Parcialmente observable\n",
        "        * Estocástico\n",
        "        * Secuencial\n",
        "        * Dinámico\n",
        "        * Continuo\n",
        "        * Multiagente\n",
        "\n",
        "        c. El juego Pacman.\n",
        "\n",
        "        * Parcialmente observable\n",
        "        * Estocástico\n",
        "        * Secuencial\n",
        "        * Dinámico\n",
        "        * Discreto\n",
        "        * Multiagente\n",
        "\n",
        "        d. El truco.\n",
        "\n",
        "        * Parcialmente observable\n",
        "        * Estocástico\n",
        "        * Secuencial\n",
        "        * Estático\n",
        "        * Discreto\n",
        "        * Multiagente\n",
        "\n",
        "        e. Las damas.\n",
        "\n",
        "        * Totalmente observable\n",
        "        * Determinista\n",
        "        * Secuencial\n",
        "        * Estático\n",
        "        * Discreto\n",
        "        * Multiagente\n",
        "\n",
        "        f. El juego tres en raya.\n",
        "\n",
        "        * Totalmente observable\n",
        "        * Determinista\n",
        "        * Secuencial\n",
        "        * Estático\n",
        "        * Discreto\n",
        "        * Multiagente\n",
        "\n",
        "        g. Un jugador de Pokémon Go.\n",
        "\n",
        "        * Parcialmente observable\n",
        "        * Estocástico\n",
        "        * Secuencial\n",
        "        * Dinámico\n",
        "        * Continuo\n",
        "        * Agente individual\n",
        "\n",
        "        h. Un robot explorador autónomo de Marte.\n",
        "\n",
        "        * Parcialmente observable\n",
        "        * Estocástico\n",
        "        * Secuencial\n",
        "        * Dinámico\n",
        "        * Continuo\n",
        "        * Agente individual"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. Elabore una tabla REAS para los siguientes entornos de trabajo:\n",
        "\n",
        "        a. Crucigrama.\n",
        "\n",
        "        b. Taxi circulando.\n",
        "\n",
        "        c. Robot clasificador de piezas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    | Nombre | Edad | Ciudad |\n",
        "    |---|---|---|\n",
        "    | Juan | 30 | Madrid |\n",
        "    | Maria | 25 | Barcelona |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicios Prácticos\n",
        "\n",
        "8. La Hormiga de Langton es un agente capaz de modificar el estado de la casilla en la que se encuentra para colorearla o bien de blanco o de negro. Al comenzar, la ubicación de la hormiga es una casilla aleatoria y mira hacia una de las cuatro casillas adyacentes. Si...\n",
        "\n",
        "* ... la casilla sobre la que está es blanca, cambia el color del cuadrado, gira noventa grados a la derecha y avanza un cuadrado.\n",
        "\n",
        "* ... la casilla sobre la que está es negra, cambia el color del cuadrado, gira noventa grados a la izquierda y avanza un cuadrado.\n",
        "\n",
        "    Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:\n",
        "\n",
        "    ¿Observa que se repite algún patrón? De ser así, ¿a partir de qué iteración?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pygame\n",
        "import numpy as np\n",
        "\n",
        "# --- Config ---\n",
        "CELL_SIZE = 8\n",
        "GRID_WIDTH = 100\n",
        "GRID_HEIGHT = 80\n",
        "FPS = 60\n",
        "\n",
        "# Colors\n",
        "WHITE = (255, 255, 255)\n",
        "BLACK = (0, 0, 0)\n",
        "ANT_COLOR = (255, 0, 0)\n",
        "\n",
        "# Directions: 0 = up, 1 = right, 2 = down, 3 = left\n",
        "DIRS = [(0, -1), (1, 0), (0, 1), (-1, 0)]\n",
        "\n",
        "pygame.init()\n",
        "screen = pygame.display.set_mode((GRID_WIDTH * CELL_SIZE, GRID_HEIGHT * CELL_SIZE))\n",
        "pygame.display.set_caption(\"Hormiga de Langton\")\n",
        "clock = pygame.time.Clock()\n",
        "\n",
        "# Grid: 0 = white, 1 = black\n",
        "grid = np.zeros((GRID_HEIGHT, GRID_WIDTH), dtype=int)\n",
        "\n",
        "# Ant position and direction\n",
        "ant_x, ant_y = GRID_WIDTH // 2, GRID_HEIGHT // 2\n",
        "ant_dir = 0  # facing up\n",
        "\n",
        "running = True\n",
        "paused = False\n",
        "\n",
        "def draw_grid(surface, grid, ant_pos):\n",
        "    surface.fill(WHITE)\n",
        "    for y in range(GRID_HEIGHT):\n",
        "        for x in range(GRID_WIDTH):\n",
        "            if grid[y, x] == 1:\n",
        "                pygame.draw.rect(surface, BLACK, (x * CELL_SIZE, y * CELL_SIZE, CELL_SIZE, CELL_SIZE))\n",
        "    # Draw ant\n",
        "    ax, ay = ant_pos\n",
        "    pygame.draw.rect(surface, ANT_COLOR, (ax * CELL_SIZE, ay * CELL_SIZE, CELL_SIZE, CELL_SIZE))\n",
        "    pygame.display.flip()\n",
        "\n",
        "def step(grid, ant_x, ant_y, ant_dir):\n",
        "    if grid[ant_y, ant_x] == 0:  # white → turn right\n",
        "        ant_dir = (ant_dir + 1) % 4\n",
        "        grid[ant_y, ant_x] = 1\n",
        "    else:  # black → turn left\n",
        "        ant_dir = (ant_dir - 1) % 4\n",
        "        grid[ant_y, ant_x] = 0\n",
        "\n",
        "    dx, dy = DIRS[ant_dir]\n",
        "    ant_x = (ant_x + dx) % GRID_WIDTH\n",
        "    ant_y = (ant_y + dy) % GRID_HEIGHT\n",
        "    return grid, ant_x, ant_y, ant_dir\n",
        "\n",
        "while running:\n",
        "    for event in pygame.event.get():\n",
        "        if event.type == pygame.QUIT:\n",
        "            running = False\n",
        "        elif event.type == pygame.KEYDOWN:\n",
        "            if event.key == pygame.K_SPACE:\n",
        "                paused = not paused\n",
        "            elif event.key == pygame.K_c:\n",
        "                grid[:] = 0\n",
        "                ant_x, ant_y = GRID_WIDTH // 2, GRID_HEIGHT // 2\n",
        "                ant_dir = 0\n",
        "\n",
        "    if not paused:\n",
        "        grid, ant_x, ant_y, ant_dir = step(grid, ant_x, ant_y, ant_dir)\n",
        "\n",
        "    draw_grid(screen, grid, (ant_x, ant_y))\n",
        "    clock.tick(FPS)\n",
        "\n",
        "pygame.quit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "9. El Juego de la Vida de Conway consiste en un tablero donde cada casilla representa una célula, de manera que a cada célula le rodean 8 vecinas. Las células tienen dos estados: están *vivas* o *muertas*. En cada iteración, el estado de todas las células se tiene en cuenta para calcular el estado siguiente en simultáneo de acuerdo a las siguientes acciones:\n",
        "\n",
        "* Nacer: Si una célula muerta tiene exactamente 3 células vecinas vivas, dicha célula pasa a estar viva.\n",
        "\n",
        "* Morir: Una célula viva puede morir sobrepoblación cuando tiene más de tres vecinos alrededor o por aislamiento si tiene solo un vecino o ninguno.\n",
        "\n",
        "* Vivir: una célula se mantiene viva si tiene 2 o 3 vecinos a su alrededor.\n",
        "\n",
        "    Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (Temp/ipykernel_20432/2043649405.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\jero0\\AppData\\Local\\Temp/ipykernel_20432/2043649405.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    hola que tal\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import pygame\n",
        "import numpy as np\n",
        "\n",
        "# --- Config ---\n",
        "Celula_SIZE = 10\n",
        "Grilla_WIDTH = 80\n",
        "Grilla_HEIGHT = 60\n",
        "FPS = 30\n",
        "\n",
        "# Colors\n",
        "BLACK = (0, 0, 0)\n",
        "WHITE = (255, 255, 255)\n",
        "\n",
        "pygame.init()\n",
        "screen = pygame.display.set_mode((Grilla_WIDTH * Celula_SIZE, Grilla_HEIGHT * Celula_SIZE))\n",
        "pygame.display.set_caption(\"Conway's Game of Life\")\n",
        "clock = pygame.time.Clock()\n",
        "\n",
        "# Grilla: 0 = dead, 1 = alive\n",
        "Grilla = np.zeros((Grilla_HEIGHT, Grilla_WIDTH), dtype=int)\n",
        "\n",
        "running = True\n",
        "paused = True\n",
        "\n",
        "def draw_Grilla(surface, Grilla):\n",
        "    surface.fill(BLACK)\n",
        "    for y in range(Grilla_HEIGHT):\n",
        "        for x in range(Grilla_WIDTH):\n",
        "            if Grilla[y, x] == 1:\n",
        "                rect = pygame.Rect(x * Celula_SIZE, y * Celula_SIZE, Celula_SIZE, Celula_SIZE)\n",
        "                pygame.draw.rect(surface, WHITE, rect)\n",
        "    pygame.display.flip()\n",
        "\n",
        "def update_Grilla(Grilla):\n",
        "    GrillaNueva = np.copy(Grilla)\n",
        "    for y in range(Grilla_HEIGHT):\n",
        "        for x in range(Grilla_WIDTH):\n",
        "            # Count alive neighbors\n",
        "            neighbors = np.sum(Grilla[max(0, y-1):min(Grilla_HEIGHT, y+2),\n",
        "                                    max(0, x-1):min(Grilla_WIDTH, x+2)]) - Grilla[y, x]\n",
        "            # Rules\n",
        "            if Grilla[y, x] == 1 and (neighbors < 2 or neighbors > 3):\n",
        "                GrillaNueva[y, x] = 0\n",
        "            elif Grilla[y, x] == 0 and neighbors == 3:\n",
        "                GrillaNueva[y, x] = 1\n",
        "    return GrillaNueva\n",
        "\n",
        "while running:\n",
        "    for event in pygame.event.get():\n",
        "        if event.type == pygame.QUIT:\n",
        "            running = False\n",
        "        elif event.type == pygame.KEYDOWN:\n",
        "            if event.key == pygame.K_SPACE:\n",
        "                paused = not paused\n",
        "            elif event.key == pygame.K_c:\n",
        "                Grilla[:] = 0\n",
        "        elif event.type == pygame.MOUSEBUTTONDOWN:\n",
        "            mx, my = pygame.mouse.get_pos()\n",
        "            gx, gy = mx // Celula_SIZE, my // Celula_SIZE\n",
        "            Grilla[gy, gx] = 1 - Grilla[gy, gx]  # Toggle Celula\n",
        "\n",
        "    if not paused:\n",
        "        Grilla = update_Grilla(Grilla)\n",
        "\n",
        "    draw_Grilla(screen, Grilla)\n",
        "    clock.tick(FPS)\n",
        "\n",
        "pygame.quit()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oXcAF__NmgG5"
      },
      "source": [
        "# Bibliografía\n",
        "\n",
        "[Russell, S. & Norvig, P. (2004) _Inteligencia Artificial: Un Enfoque Moderno_. Pearson Educación S.A. (2a Ed.) Madrid, España](https://www.academia.edu/8241613/Inteligencia_Aritificial_Un_Enfoque_Moderno_2da_Edici%C3%B3n_Stuart_J_Russell_y_Peter_Norvig)\n",
        "\n",
        "[Poole, D. & Mackworth, A. (2023) _Artificial Intelligence: Foundations of Computational Agents_. Cambridge University Press (3a Ed.) Vancouver, Canada](https://artint.info/3e/html/ArtInt3e.html)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
